{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfef36ef-7ac8-4862-b2b2-e39f06c07396",
   "metadata": {},
   "source": [
    "# Урок 15. Консультация по курсовому проекту. Создание чат-бота в Telegram\n",
    "\n",
    "* Продумать тему курсового проекта.\n",
    "* Подготовить данные для обучения.\n",
    "* Продумать интенты на которые вы будете обучаться.\n",
    "\n",
    "Для сдачи задания необходимо написать:\n",
    "* На какую тему ваш бот будет общаться (на каких датасетах планируете обучать модели)\n",
    "* Написать на какие интенты вы будете обучать бота\n",
    "\n",
    "\n",
    "Примеры интентов\n",
    "* болталка\n",
    "* погода в городе\n",
    "* время в городе\n",
    "* праздники\n",
    "* фильмы\n",
    "* покупка товара\n",
    "* можно добавить что-то своё\n",
    "\n",
    "Из обязательных (всего обязательно 3-ри интента) и один из них - болталка\n",
    "\n",
    "Выбранные интенты:\n",
    "\n",
    "1. болталка (обязательно)\n",
    "2. текущее время\n",
    "3. переводчик с английского (модель, созданная на 10-ом уроке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6892146-cf5f-42ec-9379-2fbc4ed533ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-telegram-bot pymorphy2 stop_words annoy gensim catboost --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ceca2d-c0da-4959-8315-5f62ce211dd9",
   "metadata": {
    "id": "H1aosZC2FXIj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import string\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import annoy\n",
    "from multiprocessing import cpu_count\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "from catboost import CatBoostClassifier\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, CallbackContext, filters as Filters\n",
    "from telegram import Update\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from chat import preprocess_txt, tqdm_preprocess_txt, check_in_list, embed_txt\n",
    "from tools import paralell_execution, ar_split_eq_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e9e8b-0c36-450c-a19c-214aba020030",
   "metadata": {},
   "source": [
    "## Интент болталки\n",
    "\n",
    "Тренируем и сохраняем для дальнейшего использования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e1dc524-fe80-49fc-bf16-f81649706208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e4e8ebed1e421881f089d9111d70da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Подготавливаем ответы и вопросы для обучения\n",
    "question = None\n",
    "written = False\n",
    "with open(\"prepared_answers.txt\", \"w\") as fout:\n",
    "    with open(\"./Otvety.txt\", \"r\") as fin:\n",
    "        for line in tqdm_notebook(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26f6111-5c90-4b47-9f58-3112f67b4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a47fe521-0a55-4cee-a29f-c62d0121dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lines = None\n",
    "with open(\"./Otvety.txt\", \"r\") as f:\n",
    "    file_lines = list(f)[:500000]\n",
    "\n",
    "args_parallel = []\n",
    "for lines in ar_split_eq_cpu(file_lines):\n",
    "    args_parallel.append({\n",
    "        'lines': lines,\n",
    "        'sw': sw, \n",
    "        'morpher': morpher, \n",
    "        'exclude': exclude, \n",
    "        'skip_stop_word': True\n",
    "    })\n",
    "\n",
    "# запускаем процесс параллельных вычислений\n",
    "res = paralell_execution(func=tqdm_preprocess_txt,\n",
    "                         arg=args_parallel,\n",
    "                         method='multiprocessing')\n",
    "\n",
    "sentences = [item for row in res for item in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5edaba-8f87-45ac-8060-7e92fbd58af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n"
     ]
    }
   ],
   "source": [
    "# Сохраняем результаты\n",
    "with open('./sentences.pkl', 'wb') as f:\n",
    "   pickle.dump(sentences, f)\n",
    "\n",
    "with open('./sentences.pkl', 'rb') as f:\n",
    "  sentences = pickle.load(f)\n",
    "\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afab75bc-de8d-4427-a605-19bbaae54004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тренируем и сохраняем модель fasttext\n",
    "sentences = [i for i in sentences if len(i) > 2] \n",
    "modelFT = FastText(sentences=sentences, \n",
    "                   min_count=1, \n",
    "                   window=5, \n",
    "                   workers=cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b1ba331-7360-4d42-a785-f09802757888",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT.save(\"./ft_model\")\n",
    "modelFT = FastText.load(\"./ft_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "473c2c88-9f17-4c8e-ad50-f1f225f900d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepared_answers_preprocess_txt(lines):\n",
    "    index_map = {}\n",
    "    vector_ft_list = []\n",
    "    counter_list = []\n",
    "    question_list = []\n",
    "    for counter, line in enumerate(tqdm_notebook(lines)):\n",
    "        n_ft = 0\n",
    "        spls = line.replace('\\n', '').split(\"\\t\")\n",
    "        index_map[counter] = spls[1].replace('\\n', '')\n",
    "        question = preprocess_txt(line=spls[0], \n",
    "                                  sw=sw, \n",
    "                                  morpher=morpher, \n",
    "                                  exclude=exclude, \n",
    "                                  skip_stop_word=True)\n",
    "        vector_ft = np.zeros(100)\n",
    "        for word in question:\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word]\n",
    "                n_ft += 1\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        \n",
    "        vector_ft_list.append(vector_ft)\n",
    "        counter_list.append(counter)\n",
    "        question_list.append(question)\n",
    "        \n",
    "    return {'vector_ft_list': vector_ft_list, \n",
    "            'index_map': index_map, \n",
    "            'counter_list': counter_list, \n",
    "            'question_list': question_list}\n",
    "    \n",
    "file_lines = None\n",
    "with open(\"prepared_answers.txt\", \"r\") as f:\n",
    "    file_lines = list(f)\n",
    "\n",
    "args_parallel = []\n",
    "for lines in ar_split_eq_cpu(file_lines):\n",
    "    args_parallel.append(lines)\n",
    "\n",
    "# запускаем процесс параллельных вычислений\n",
    "res_raw = paralell_execution(func=prepared_answers_preprocess_txt,\n",
    "                         arg=args_parallel,\n",
    "                         method='multiprocessing')\n",
    "\n",
    "\n",
    "ft_index = annoy.AnnoyIndex(100 ,'angular')\n",
    "glob_counter = 0\n",
    "index_map = {}\n",
    "index_map_questions = {}\n",
    "for item in res_raw:\n",
    "    vector_ft_list = item['vector_ft_list']\n",
    "    index_map_list = item['index_map']\n",
    "    counter_list = item['counter_list']\n",
    "    question_list = item['question_list']\n",
    "    \n",
    "    for counter in counter_list:\n",
    "        index_map[glob_counter] = index_map_list[counter]\n",
    "        index_map_questions[glob_counter] = question_list[counter]\n",
    "        ft_index.add_item(glob_counter, vector_ft_list[counter])\n",
    "        glob_counter += 1\n",
    "\n",
    "ft_index.build(10)\n",
    "ft_index.save('./speaker.ann')\n",
    "ft_index.load('./speaker.ann') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20d9bbea-d38e-40b7-9207-6fc89837997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index_map.pkl', 'wb') as fp:\n",
    "   pickle.dump(index_map, fp)\n",
    "\n",
    "with open('index_map.pkl', 'rb') as f:\n",
    "  index_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfb21981-288e-4c55-aedb-5202335d3ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "# texts = [\" \".join(v) for v in index_map_questions.values()]\n",
    "# vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3f30d7c-148b-462a-a772-a44ace5358a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Сохраняем результаты\n",
    "# vectorizer = None\n",
    "# with open('./vectorizer.pkl', 'wb') as f:\n",
    "#    pickle.dump(vectorizer, f)\n",
    "\n",
    "# with open('./vectorizer.pkl', 'rb') as f:\n",
    "#   vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55ed40c3-5797-4223-96d5-350984292ca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params_chat = {\n",
    "    'sw': sw, \n",
    "    'morpher': morpher, \n",
    "    'exclude': exclude, \n",
    "    'modelFT': modelFT, \n",
    "}\n",
    "with open('./params_chat.pkl', 'wb') as f:\n",
    "    pickle.dump(params_chat, f)\n",
    "with open('./params_chat.pkl', 'rb') as f:\n",
    "    params_chat = pickle.load(f)\n",
    "    \n",
    "ft_index = annoy.AnnoyIndex(100 ,'angular')\n",
    "ft_index.load('./speaker.ann') \n",
    "params_chat['ft_index'] = ft_index "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fb3e16-da41-4424-bbe4-4b34e0cde96b",
   "metadata": {},
   "source": [
    "## Интент текущего времени сервера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e2a3d6d-2129-4c3b-8d87-229f11cee27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cur_time():\n",
    "    now = datetime.now()     \n",
    "    return f'Текущее время сервера: {now.strftime(\"%d-%m-%Y %H:%M:%S\")}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807f1d50-b72d-4eab-91ab-d11ad54ced73",
   "metadata": {},
   "source": [
    "## Интент перевода на английский с помощью нейронной сети из ДЗ 10-го урока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc45fdbc-c1bf-4c9d-975c-64c4f932cb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 16:41:00.825008: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good afternoon . \n",
      "it's a good choice . \n"
     ]
    }
   ],
   "source": [
    "from translator import Encoder, Decoder, preprocess_sentence, evaluate, translate\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Загружаем предобученные модели\n",
    "inp_lang = None\n",
    "targ_lang = None\n",
    "\n",
    "with open('./inp_lang.pickle', \"rb\") as f:\n",
    "    inp_lang = pickle.load(f)\n",
    "with open('./targ_lang.pickle', \"rb\") as f:\n",
    "    targ_lang = pickle.load(f)\n",
    "    \n",
    "max_length_targ = 12\n",
    "max_length_inp = 16\n",
    "BATCH_SIZE = 64\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Сохраняем параметры в файл для более быстрой загрузки в файле кода бота\n",
    "params_translator = {\n",
    "    'max_length_targ': max_length_targ, \n",
    "    'max_length_inp': max_length_inp, \n",
    "    'inp_lang': inp_lang, \n",
    "    'targ_lang': targ_lang, \n",
    "    'units': units, \n",
    "    'vocab_inp_size': vocab_inp_size, \n",
    "    'vocab_tar_size': vocab_tar_size, \n",
    "    'embedding_dim': embedding_dim, \n",
    "    'BATCH_SIZE': BATCH_SIZE, \n",
    "}\n",
    "with open('./params_translator.pkl', 'wb') as f:\n",
    "   pickle.dump(params_translator, f)\n",
    "with open('./params_translator.pkl', 'rb') as f:\n",
    "  params_translator = pickle.load(f)\n",
    "\n",
    "encoder = Encoder(params_translator['vocab_inp_size'], \n",
    "                  params_translator['embedding_dim'], \n",
    "                  params_translator['units'], \n",
    "                  params_translator['BATCH_SIZE'])\n",
    "decoder = Decoder(params_translator['vocab_tar_size'], \n",
    "                  params_translator['embedding_dim'], \n",
    "                  params_translator['units'], \n",
    "                  params_translator['BATCH_SIZE'])\n",
    "\n",
    "checkpoint_dir = './training_nmt_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "params_translator['encoder'] = encoder\n",
    "params_translator['decoder'] = decoder\n",
    "\n",
    "print( translate('переведи добрый день', params_translator) )\n",
    "print( translate('переведи хороший выбор', params_translator) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5faacec-0597-4684-9455-66a985d75841",
   "metadata": {},
   "source": [
    "## Функция генерации ответов бота к пользователю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "384194a0-f48a-4b38-abf8-e3d791275e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 17:34:54.746008: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "from tg import process\n",
    "from chat import load_chat_params\n",
    "chat_params = load_chat_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b67c6e3a-9331-410a-a9b0-b623a6dff4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Текущее время сервера: 03-12-2023 15:33:28'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process('который час', chat_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca60138c-e312-4f65-84bd-67d8cab59506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good afternoon . '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process('переведи добрый день', chat_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "972a8bbd-ed1c-472f-94db-d0c66cea77a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Мы молчим???Нас тут не угомонишь.... '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process('давай поговорим', chat_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f852dc76-d5f4-43c7-8edf-38be00fa4c44",
   "metadata": {},
   "source": [
    "## Телеграм бот\n",
    "\n",
    "Бот запускается через файл, в ноутбуке он не работает.\n",
    "\n",
    "python3 tg.py\n",
    "\n",
    "Результат работы бота:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a6881a-21f3-4ff3-8a97-8b93f8fb792d",
   "metadata": {},
   "source": [
    "![](result.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}